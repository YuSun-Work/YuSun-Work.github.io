---
title: "Multimodal Emotion Recognition"
collection: project
type: "Idea Stage"
permalink: /project/2023-project-09
venue: "Lanzhou University"
date: 2023-1-1
location: "Lanzhou, China"
---

Emotion recognition is essential for building empathetic and socially intelligent artificial intelligence. Unimodal systems relying solely on text or audio have limitations in capturing the nuanced affective states conveyed through multiple, complementary modalities in human communication. To address this, we present a multimodal framework for emotion classification that extracts features from textual, acoustic and visual inputs. Our model employs early and late fusion techniques to integrate information from different modalities effectively. Experiments on the multimodal emotion recognition dataset show our approach outperforms previous unimodal and early fusion methods, demonstrating the benefits of late fusion for modeling inter-modal dependencies. Ablation studies confirm the complementary nature of textual, acoustic and visual cues for fine-grained emotion recognition. Our work provides insights into multimodal fusion techniques and the utility of leveraging multimodal signals to better infer human emotive states.
